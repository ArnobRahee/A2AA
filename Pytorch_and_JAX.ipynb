{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0GIVUqS3yDeKgguueDpvg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArnobRahee/A2AA/blob/main/Pytorch_and_JAX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Downloading JRAPH**"
      ],
      "metadata": {
        "id": "XbUytcjRAGuz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atAjFBiSABpG",
        "outputId": "40d87d3a-f3b2-4d7e-f157-31cd32dcf09d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/deepmind/jraph.git\n",
            "  Cloning https://github.com/deepmind/jraph.git to /tmp/pip-req-build-exj6605l\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/deepmind/jraph.git /tmp/pip-req-build-exj6605l\n",
            "  Resolved https://github.com/deepmind/jraph.git to commit 51f5990104f7374492f8f3ea1cbc47feb411c69c\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.10/dist-packages (from jraph==0.0.6.dev0) (0.4.23)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from jraph==0.0.6.dev0) (0.4.23+cuda12.cudnn89)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from jraph==0.0.6.dev0) (1.25.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.1.55->jraph==0.0.6.dev0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.1.55->jraph==0.0.6.dev0) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.1.55->jraph==0.0.6.dev0) (1.11.4)\n",
            "Building wheels for collected packages: jraph\n",
            "  Building wheel for jraph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jraph: filename=jraph-0.0.6.dev0-py3-none-any.whl size=91245 sha256=c261ca6e8df3b1f56ef5113091634867aa175ce90d19715d928f04d7f8f6c42f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8527d7q4/wheels/76/61/34/8fb9aa4dac00d471de4a5f7157614181de683c445fc2d640db\n",
            "Successfully built jraph\n",
            "Installing collected packages: jraph\n",
            "Successfully installed jraph-0.0.6.dev0\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from flax) (1.25.2)\n",
            "Requirement already satisfied: jax>=0.4.19 in /usr/local/lib/python3.10/dist-packages (from flax) (0.4.23)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax) (1.0.7)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax) (0.1.9)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax) (13.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax) (4.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax) (6.0.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.19->flax) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.19->flax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.19->flax) (1.11.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (1.4.0)\n",
            "Requirement already satisfied: chex>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (0.1.85)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->flax) (0.4.23+cuda12.cudnn89)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.6.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax) (3.20.3)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.7->optax->flax) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (6.1.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax) (3.17.0)\n",
            "Collecting dm-haiku\n",
            "  Downloading dm_haiku-0.0.11-py3-none-any.whl (370 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.0/371.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (1.4.0)\n",
            "Collecting jmp>=0.0.2 (from dm-haiku)\n",
            "  Downloading jmp-0.0.4-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (1.25.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (0.9.0)\n",
            "Requirement already satisfied: flax>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (0.8.1)\n",
            "Requirement already satisfied: jax>=0.4.19 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku) (0.4.23)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku) (1.0.7)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku) (0.1.9)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku) (13.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku) (4.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku) (6.0.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.19->flax>=0.7.1->dm-haiku) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.19->flax>=0.7.1->dm-haiku) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.19->flax>=0.7.1->dm-haiku) (1.11.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.1->dm-haiku) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.1->dm-haiku) (2.16.1)\n",
            "Requirement already satisfied: chex>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from optax->flax>=0.7.1->dm-haiku) (0.1.85)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->flax>=0.7.1->dm-haiku) (0.4.23+cuda12.cudnn89)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.7.1->dm-haiku) (1.6.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.7.1->dm-haiku) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.7.1->dm-haiku) (3.20.3)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.7->optax->flax>=0.7.1->dm-haiku) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.1->dm-haiku) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.1->dm-haiku) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.1->dm-haiku) (6.1.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.1->dm-haiku) (3.17.0)\n",
            "Installing collected packages: jmp, dm-haiku\n",
            "Successfully installed dm-haiku-0.0.11 jmp-0.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/deepmind/jraph.git\n",
        "!pip install flax\n",
        "!pip install dm-haiku"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Importing Libraries of both pytorch and JAX**"
      ],
      "metadata": {
        "id": "r4VFZJwwAZvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "import pickle\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgb\n",
        "import matplotlib\n",
        "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
        "import seaborn as sns\n",
        "sns.reset_orig()\n",
        "sns.set()\n",
        "#JRAPH\n",
        "%matplotlib inline\n",
        "import functools\n",
        "import matplotlib.pyplot as plt\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.tree_util as tree\n",
        "import jraph\n",
        "import flax\n",
        "import haiku as hk\n",
        "import optax\n",
        "import pickle\n",
        "import numpy as onp\n",
        "import networkx as nx\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
        "\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "# Torchvision\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "# PyTorch Lightning\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
        "    !pip install --quiet pytorch-lightning>=1.4\n",
        "    import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "\n",
        "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
        "DATASET_PATH = \"../data\"\n",
        "# Path to the folder where the pretrained models are saved\n",
        "CHECKPOINT_PATH = \"../saved_models/tutorial7\"\n",
        "\n",
        "# Setting the seed\n",
        "pl.seed_everything(42)\n",
        "\n",
        "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uka0N-8rAYC8",
        "outputId": "674f57ea-fc52-47ef-dbdb-038820b3ed7c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-57afe3eada42>:12: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
            "  set_matplotlib_formats('svg', 'pdf') # For export\n",
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "from urllib.error import HTTPError\n",
        "# Github URL where saved models are stored for this tutorial\n",
        "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/\"\n",
        "# Files to download\n",
        "pretrained_files = [\"NodeLevelMLP.ckpt\", \"NodeLevelGNN.ckpt\", \"GraphLevelGraphConv.ckpt\"]\n",
        "\n",
        "# Create checkpoint path if it doesn't exist yet\n",
        "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
        "\n",
        "# For each file, check whether it already exists. If not, try downloading it.\n",
        "for file_name in pretrained_files:\n",
        "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
        "    if \"/\" in file_name:\n",
        "        os.makedirs(file_path.rsplit(\"/\",1)[0], exist_ok=True)\n",
        "    if not os.path.isfile(file_path):\n",
        "        file_url = base_url + file_name\n",
        "        print(f\"Downloading {file_url}...\")\n",
        "        try:\n",
        "            urllib.request.urlretrieve(file_url, file_path)\n",
        "        except HTTPError as e:\n",
        "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u44HB4tJAvQL",
        "outputId": "e5a798d5-bea0-44c4-86b2-e6b3c3b93b32"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelMLP.ckpt...\n",
            "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/NodeLevelGNN.ckpt...\n",
            "Downloading https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial7/GraphLevelGraphConv.ckpt...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pytorch**"
      ],
      "metadata": {
        "id": "ZAcyNg4EAyqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_out):\n",
        "        super().__init__()\n",
        "        self.projection = nn.Linear(c_in, c_out)\n",
        "\n",
        "    def forward(self, node_feats, adj_matrix):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            node_feats - Tensor with node features of shape [batch_size, num_nodes, c_in]\n",
        "            adj_matrix - Batch of adjacency matrices of the graph. If there is an edge from i to j, adj_matrix[b,i,j]=1 else 0.\n",
        "                         Supports directed edges by non-symmetric matrices. Assumes to already have added the identity connections.\n",
        "                         Shape: [batch_size, num_nodes, num_nodes]\n",
        "        \"\"\"\n",
        "        # Num neighbours = number of incoming edges\n",
        "        num_neighbours = adj_matrix.sum(dim=-1, keepdims=True)\n",
        "        node_feats = self.projection(node_feats)\n",
        "        node_feats = torch.bmm(adj_matrix, node_feats)\n",
        "        node_feats = node_feats / num_neighbours\n",
        "        return node_feats"
      ],
      "metadata": {
        "id": "Reh9kH9eA1e6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_feats = torch.arange(8, dtype=torch.float32).view(1, 4, 2)\n",
        "adj_matrix = torch.Tensor([[[1, 1, 0, 0],\n",
        "                            [1, 1, 1, 1],\n",
        "                            [0, 1, 1, 1],\n",
        "                            [0, 1, 1, 1]]])\n",
        "\n",
        "print(\"Node features:\\n\", node_feats)\n",
        "print(\"\\nAdjacency matrix:\\n\", adj_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRG4Ajb_A5uC",
        "outputId": "133f3268-30f0-42d4-f0a1-d934e059bb44"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node features:\n",
            " tensor([[[0., 1.],\n",
            "         [2., 3.],\n",
            "         [4., 5.],\n",
            "         [6., 7.]]])\n",
            "\n",
            "Adjacency matrix:\n",
            " tensor([[[1., 1., 0., 0.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [0., 1., 1., 1.],\n",
            "         [0., 1., 1., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GATLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_out, num_heads=1, concat_heads=True, alpha=0.2):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimensionality of input features\n",
        "            c_out - Dimensionality of output features\n",
        "            num_heads - Number of heads, i.e. attention mechanisms to apply in parallel. The\n",
        "                        output features are equally split up over the heads if concat_heads=True.\n",
        "            concat_heads - If True, the output of the different heads is concatenated instead of averaged.\n",
        "            alpha - Negative slope of the LeakyReLU activation.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.concat_heads = concat_heads\n",
        "        if self.concat_heads:\n",
        "            assert c_out % num_heads == 0, \"Number of output features must be a multiple of the count of heads.\"\n",
        "            c_out = c_out // num_heads\n",
        "\n",
        "        # Sub-modules and parameters needed in the layer\n",
        "        self.projection = nn.Linear(c_in, c_out * num_heads)\n",
        "        self.a = nn.Parameter(torch.Tensor(num_heads, 2 * c_out)) # One per head\n",
        "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
        "\n",
        "        # Initialization from the original implementation\n",
        "        nn.init.xavier_uniform_(self.projection.weight.data, gain=1.414)\n",
        "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
        "\n",
        "    def forward(self, node_feats, adj_matrix, print_attn_probs=False):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            node_feats - Input features of the node. Shape: [batch_size, c_in]\n",
        "            adj_matrix - Adjacency matrix including self-connections. Shape: [batch_size, num_nodes, num_nodes]\n",
        "            print_attn_probs - If True, the attention weights are printed during the forward pass (for debugging purposes)\n",
        "        \"\"\"\n",
        "        batch_size, num_nodes = node_feats.size(0), node_feats.size(1)\n",
        "\n",
        "        # Apply linear layer and sort nodes by head\n",
        "        node_feats = self.projection(node_feats)\n",
        "        node_feats = node_feats.view(batch_size, num_nodes, self.num_heads, -1)\n",
        "\n",
        "        # We need to calculate the attention logits for every edge in the adjacency matrix\n",
        "        # Doing this on all possible combinations of nodes is very expensive\n",
        "        # => Create a tensor of [W*h_i||W*h_j] with i and j being the indices of all edges\n",
        "        edges = adj_matrix.nonzero(as_tuple=False) # Returns indices where the adjacency matrix is not 0 => edges\n",
        "        node_feats_flat = node_feats.view(batch_size * num_nodes, self.num_heads, -1)\n",
        "        edge_indices_row = edges[:,0] * num_nodes + edges[:,1]\n",
        "        edge_indices_col = edges[:,0] * num_nodes + edges[:,2]\n",
        "        a_input = torch.cat([\n",
        "            torch.index_select(input=node_feats_flat, index=edge_indices_row, dim=0),\n",
        "            torch.index_select(input=node_feats_flat, index=edge_indices_col, dim=0)\n",
        "        ], dim=-1) # Index select returns a tensor with node_feats_flat being indexed at the desired positions along dim=0\n",
        "\n",
        "        # Calculate attention MLP output (independent for each head)\n",
        "        attn_logits = torch.einsum('bhc,hc->bh', a_input, self.a)\n",
        "        attn_logits = self.leakyrelu(attn_logits)\n",
        "\n",
        "        # Map list of attention values back into a matrix\n",
        "        attn_matrix = attn_logits.new_zeros(adj_matrix.shape+(self.num_heads,)).fill_(-9e15)\n",
        "        attn_matrix[adj_matrix[...,None].repeat(1,1,1,self.num_heads) == 1] = attn_logits.reshape(-1)\n",
        "\n",
        "        # Weighted average of attention\n",
        "        attn_probs = F.softmax(attn_matrix, dim=2)\n",
        "        if print_attn_probs:\n",
        "            print(\"Attention probs\\n\", attn_probs.permute(0, 3, 1, 2))\n",
        "        node_feats = torch.einsum('bijh,bjhc->bihc', attn_probs, node_feats)\n",
        "\n",
        "        # If heads should be concatenated, we can do this by reshaping. Otherwise, take mean\n",
        "        if self.concat_heads:\n",
        "            node_feats = node_feats.reshape(batch_size, num_nodes, -1)\n",
        "        else:\n",
        "            node_feats = node_feats.mean(dim=2)\n",
        "\n",
        "        return node_feats"
      ],
      "metadata": {
        "id": "ZITnqOk5A8vC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = GATLayer(2, 2, num_heads=2)\n",
        "layer.projection.weight.data = torch.Tensor([[1., 0.], [0., 1.]])\n",
        "layer.projection.bias.data = torch.Tensor([0., 0.])\n",
        "layer.a.data = torch.Tensor([[-0.2, 0.3], [0.1, -0.1]])\n",
        "\n",
        "with torch.no_grad():\n",
        "    out_feats = layer(node_feats, adj_matrix, print_attn_probs=True)\n",
        "\n",
        "print(\"Adjacency matrix\", adj_matrix)\n",
        "print(\"Input features\", node_feats)\n",
        "print(\"Output features\", out_feats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrcXa3mhBNiL",
        "outputId": "1c529ad8-f912-4ec0-9ff0-b5f294f45dfd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention probs\n",
            " tensor([[[[0.3543, 0.6457, 0.0000, 0.0000],\n",
            "          [0.1096, 0.1450, 0.2642, 0.4813],\n",
            "          [0.0000, 0.1858, 0.2885, 0.5257],\n",
            "          [0.0000, 0.2391, 0.2696, 0.4913]],\n",
            "\n",
            "         [[0.5100, 0.4900, 0.0000, 0.0000],\n",
            "          [0.2975, 0.2436, 0.2340, 0.2249],\n",
            "          [0.0000, 0.3838, 0.3142, 0.3019],\n",
            "          [0.0000, 0.4018, 0.3289, 0.2693]]]])\n",
            "Adjacency matrix tensor([[[1., 1., 0., 0.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [0., 1., 1., 1.],\n",
            "         [0., 1., 1., 1.]]])\n",
            "Input features tensor([[[0., 1.],\n",
            "         [2., 3.],\n",
            "         [4., 5.],\n",
            "         [6., 7.]]])\n",
            "Output features tensor([[[1.2913, 1.9800],\n",
            "         [4.2344, 3.7725],\n",
            "         [4.6798, 4.8362],\n",
            "         [4.5043, 4.7351]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch geometric\n",
        "try:\n",
        "    import torch_geometric\n",
        "except ModuleNotFoundError:\n",
        "    # Installing torch geometric packages with specific CUDA+PyTorch version.\n",
        "    # See https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html for details\n",
        "    TORCH = torch.__version__.split('+')[0]\n",
        "    CUDA = 'cu' + torch.version.cuda.replace('.','')\n",
        "\n",
        "    !pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install torch-geometric\n",
        "    import torch_geometric\n",
        "import torch_geometric.nn as geom_nn\n",
        "import torch_geometric.data as geom_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrYzUVtNBSZK",
        "outputId": "70dd3eab-b0eb-4a88-97b0-e1bfa9a9694d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_scatter-2.1.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt21cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_sparse-0.6.18%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.25.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt21cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_cluster-1.6.3%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.25.2)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt21cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (932 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m932.1/932.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.2+pt21cu121\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_layer_by_name = {\n",
        "    \"GCN\": geom_nn.GCNConv,\n",
        "    \"GAT\": geom_nn.GATConv,\n",
        "    \"GraphConv\": geom_nn.GraphConv\n",
        "}"
      ],
      "metadata": {
        "id": "szwcZfj8Bfek"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cora_dataset = torch_geometric.datasets.Planetoid(root=DATASET_PATH, name=\"Cora\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxISTQCyBiwR",
        "outputId": "9342bdb8-f39a-4633-c5bc-17d2fab863ff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cora_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffrzzNswBm8w",
        "outputId": "70a32c08-65fa-47b8-c1a3-ed68bf9ad547"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, layer_name=\"GCN\", dp_rate=0.1, **kwargs):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimension of input features\n",
        "            c_hidden - Dimension of hidden features\n",
        "            c_out - Dimension of the output features. Usually number of classes in classification\n",
        "            num_layers - Number of \"hidden\" graph layers\n",
        "            layer_name - String of the graph layer to use\n",
        "            dp_rate - Dropout rate to apply throughout the network\n",
        "            kwargs - Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        gnn_layer = gnn_layer_by_name[layer_name]\n",
        "\n",
        "        layers = []\n",
        "        in_channels, out_channels = c_in, c_hidden\n",
        "        for l_idx in range(num_layers-1):\n",
        "            layers += [\n",
        "                gnn_layer(in_channels=in_channels,\n",
        "                          out_channels=out_channels,\n",
        "                          **kwargs),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dp_rate)\n",
        "            ]\n",
        "            in_channels = c_hidden\n",
        "        layers += [gnn_layer(in_channels=in_channels,\n",
        "                             out_channels=c_out,\n",
        "                             **kwargs)]\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            x - Input features per node\n",
        "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
        "        \"\"\"\n",
        "        for l in self.layers:\n",
        "            # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
        "            # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
        "            # we can simply check the class type.\n",
        "            if isinstance(l, geom_nn.MessagePassing):\n",
        "                x = l(x, edge_index)\n",
        "            else:\n",
        "                x = l(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jHGMt80DBqaU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPModel(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, dp_rate=0.1):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimension of input features\n",
        "            c_hidden - Dimension of hidden features\n",
        "            c_out - Dimension of the output features. Usually number of classes in classification\n",
        "            num_layers - Number of hidden layers\n",
        "            dp_rate - Dropout rate to apply throughout the network\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        in_channels, out_channels = c_in, c_hidden\n",
        "        for l_idx in range(num_layers-1):\n",
        "            layers += [\n",
        "                nn.Linear(in_channels, out_channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dp_rate)\n",
        "            ]\n",
        "            in_channels = c_hidden\n",
        "        layers += [nn.Linear(in_channels, c_out)]\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            x - Input features per node\n",
        "        \"\"\"\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "VQwCB5FABtga"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NodeLevelGNN(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, model_name, **model_kwargs):\n",
        "        super().__init__()\n",
        "        # Saving hyperparameters\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        if model_name == \"MLP\":\n",
        "            self.model = MLPModel(**model_kwargs)\n",
        "        else:\n",
        "            self.model = GNNModel(**model_kwargs)\n",
        "        self.loss_module = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, data, mode=\"train\"):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.model(x, edge_index)\n",
        "\n",
        "        # Only calculate the loss on the nodes corresponding to the mask\n",
        "        if mode == \"train\":\n",
        "            mask = data.train_mask\n",
        "        elif mode == \"val\":\n",
        "            mask = data.val_mask\n",
        "        elif mode == \"test\":\n",
        "            mask = data.test_mask\n",
        "        else:\n",
        "            assert False, f\"Unknown forward mode: {mode}\"\n",
        "\n",
        "        loss = self.loss_module(x[mask], data.y[mask])\n",
        "        acc = (x[mask].argmax(dim=-1) == data.y[mask]).sum().float() / mask.sum()\n",
        "        return loss, acc\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # We use SGD here, but Adam works as well\n",
        "        optimizer = optim.SGD(self.parameters(), lr=0.1, momentum=0.9, weight_decay=2e-3)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, acc = self.forward(batch, mode=\"train\")\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('train_acc', acc)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        _, acc = self.forward(batch, mode=\"val\")\n",
        "        self.log('val_acc', acc)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        _, acc = self.forward(batch, mode=\"test\")\n",
        "        self.log('test_acc', acc)"
      ],
      "metadata": {
        "id": "EXxz3d5BBwvy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_node_classifier(model_name, dataset, **model_kwargs):\n",
        "    pl.seed_everything(42)\n",
        "    node_data_loader = geom_data.DataLoader(dataset, batch_size=1)\n",
        "\n",
        "    # Create a PyTorch Lightning trainer with the generation callback\n",
        "    root_dir = os.path.join(CHECKPOINT_PATH, \"NodeLevel\" + model_name)\n",
        "    os.makedirs(root_dir, exist_ok=True)\n",
        "    trainer = pl.Trainer(default_root_dir=root_dir,\n",
        "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
        "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
        "                         devices=1,\n",
        "                         max_epochs=200,\n",
        "                         enable_progress_bar=False) # False because epoch size is 1\n",
        "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
        "\n",
        "    # Check whether pretrained model exists. If yes, load it and skip training\n",
        "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"NodeLevel{model_name}.ckpt\")\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(\"Found pretrained model, loading...\")\n",
        "        model = NodeLevelGNN.load_from_checkpoint(pretrained_filename)\n",
        "    else:\n",
        "        pl.seed_everything()\n",
        "        model = NodeLevelGNN(model_name=model_name, c_in=dataset.num_node_features, c_out=dataset.num_classes, **model_kwargs)\n",
        "        trainer.fit(model, node_data_loader, node_data_loader)\n",
        "        model = NodeLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
        "\n",
        "    # Test best model on the test set\n",
        "    test_result = trainer.test(model, node_data_loader, verbose=False)\n",
        "    batch = next(iter(node_data_loader))\n",
        "    batch = batch.to(model.device)\n",
        "    _, train_acc = model.forward(batch, mode=\"train\")\n",
        "    _, val_acc = model.forward(batch, mode=\"val\")\n",
        "    result = {\"train\": train_acc,\n",
        "              \"val\": val_acc,\n",
        "              \"test\": test_result[0]['test_acc']}\n",
        "    return model, result"
      ],
      "metadata": {
        "id": "71NwkztFB0Da"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Small function for printing the test scores\n",
        "def print_results(result_dict):\n",
        "    if \"train\" in result_dict:\n",
        "        print(f\"Train accuracy: {(100.0*result_dict['train']):4.2f}%\")\n",
        "    if \"val\" in result_dict:\n",
        "        print(f\"Val accuracy:   {(100.0*result_dict['val']):4.2f}%\")\n",
        "    print(f\"Test accuracy:  {(100.0*result_dict['test']):4.2f}%\")"
      ],
      "metadata": {
        "id": "REYp-c19B2Wp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_mlp_model, node_mlp_result = train_node_classifier(model_name=\"MLP\",\n",
        "                                                        dataset=cora_dataset,\n",
        "                                                        c_hidden=16,\n",
        "                                                        num_layers=2,\n",
        "                                                        dp_rate=0.1)\n",
        "\n",
        "print_results(node_mlp_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHAynwTQB48Y",
        "outputId": "fff48d78-1b33-45e5-d031-af6e6a8f734d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found pretrained model, loading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.0.2 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../saved_models/tutorial7/NodeLevelMLP.ckpt`\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: ../saved_models/tutorial7/NodeLevelMLP/lightning_logs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 97.14%\n",
            "Val accuracy:   54.60%\n",
            "Test accuracy:  60.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2708. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_gnn_model, node_gnn_result = train_node_classifier(model_name=\"GNN\",\n",
        "                                                        layer_name=\"GCN\",\n",
        "                                                        dataset=cora_dataset,\n",
        "                                                        c_hidden=16,\n",
        "                                                        num_layers=2,\n",
        "                                                        dp_rate=0.1)\n",
        "print_results(node_gnn_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H9ReMdlB9sq",
        "outputId": "9a4cb157-4896-48f9-a3c7-df1c4d2200cd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found pretrained model, loading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.0.2 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../saved_models/tutorial7/NodeLevelGNN.ckpt`\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: ../saved_models/tutorial7/NodeLevelGNN/lightning_logs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 100.00%\n",
            "Val accuracy:   78.60%\n",
            "Test accuracy:  82.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tu_dataset = torch_geometric.datasets.TUDataset(root=DATASET_PATH, name=\"MUTAG\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj_akPaDCA9x",
        "outputId": "07eaadf0-74b3-46dc-919d-f13512d06af8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n",
            "Extracting ../data/MUTAG/MUTAG.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data object:\", tu_dataset.data)\n",
        "print(\"Length:\", len(tu_dataset))\n",
        "print(f\"Average label: {tu_dataset.data.y.float().mean().item():4.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EopASMAMCFAK",
        "outputId": "a56f5bd8-178d-4878-c26f-eda115091afc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data object: Data(x=[3371, 7], edge_index=[2, 7442], edge_attr=[7442, 4], y=[188])\n",
            "Length: 188\n",
            "Average label: 0.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "tu_dataset.shuffle()\n",
        "train_dataset = tu_dataset[:150]\n",
        "test_dataset = tu_dataset[150:]"
      ],
      "metadata": {
        "id": "Ekn8rAP_CIcJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_train_loader = geom_data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "graph_val_loader = geom_data.DataLoader(test_dataset, batch_size=64) # Additional loader if you want to change to a larger dataset\n",
        "graph_test_loader = geom_data.DataLoader(test_dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "iCVh9ofpCL1B"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(graph_test_loader))\n",
        "print(\"Batch:\", batch)\n",
        "print(\"Labels:\", batch.y[:10])\n",
        "print(\"Batch indices:\", batch.batch[:40])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgcvLKaKCO3q",
        "outputId": "4bb44de7-dcca-4bfe-dfcc-dbcf23d9017d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: DataBatch(edge_index=[2, 1512], x=[687, 7], edge_attr=[1512, 4], y=[38], batch=[687], ptr=[39])\n",
            "Labels: tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 0])\n",
            "Batch indices: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphLevelGNN(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, **model_kwargs):\n",
        "        super().__init__()\n",
        "        # Saving hyperparameters\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.model = GraphGNNModel(**model_kwargs)\n",
        "        self.loss_module = nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, data, mode=\"train\"):\n",
        "        x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n",
        "        x = self.model(x, edge_index, batch_idx)\n",
        "        x = x.squeeze(dim=-1)\n",
        "\n",
        "        if self.hparams.c_out == 1:\n",
        "            preds = (x > 0).float()\n",
        "            data.y = data.y.float()\n",
        "        else:\n",
        "            preds = x.argmax(dim=-1)\n",
        "        loss = self.loss_module(x, data.y)\n",
        "        acc = (preds == data.y).sum().float() / preds.shape[0]\n",
        "        return loss, acc\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.AdamW(self.parameters(), lr=1e-2, weight_decay=0.0) # High lr because of small dataset and small model\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, acc = self.forward(batch, mode=\"train\")\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('train_acc', acc)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        _, acc = self.forward(batch, mode=\"val\")\n",
        "        self.log('val_acc', acc)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        _, acc = self.forward(batch, mode=\"test\")\n",
        "        self.log('test_acc', acc)"
      ],
      "metadata": {
        "id": "nBICcrOwCkUT"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphGNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_hidden, c_out, dp_rate_linear=0.5, **kwargs):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimension of input features\n",
        "            c_hidden - Dimension of hidden features\n",
        "            c_out - Dimension of output features (usually number of classes)\n",
        "            dp_rate_linear - Dropout rate before the linear layer (usually much higher than inside the GNN)\n",
        "            kwargs - Additional arguments for the GNNModel object\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.GNN = GNNModel(c_in=c_in,\n",
        "                            c_hidden=c_hidden,\n",
        "                            c_out=c_hidden, # Not our prediction output yet!\n",
        "                            **kwargs)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Dropout(dp_rate_linear),\n",
        "            nn.Linear(c_hidden, c_out)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, batch_idx):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            x - Input features per node\n",
        "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
        "            batch_idx - Index of batch element for each node\n",
        "        \"\"\"\n",
        "        x = self.GNN(x, edge_index)\n",
        "        x = geom_nn.global_mean_pool(x, batch_idx) # Average pooling\n",
        "        x = self.head(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "nxpmICqhCRaC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_graph_classifier(model_name, **model_kwargs):\n",
        "    pl.seed_everything(42)\n",
        "\n",
        "    # Create a PyTorch Lightning trainer with the generation callback\n",
        "    root_dir = os.path.join(CHECKPOINT_PATH, \"GraphLevel\" + model_name)\n",
        "    os.makedirs(root_dir, exist_ok=True)\n",
        "    trainer = pl.Trainer(default_root_dir=root_dir,\n",
        "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
        "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
        "                         devices=1,\n",
        "                         max_epochs=500,\n",
        "                         enable_progress_bar=False)\n",
        "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
        "\n",
        "    # Check whether pretrained model exists. If yes, load it and skip training\n",
        "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"GraphLevel{model_name}.ckpt\")\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print(\"Found pretrained model, loading...\")\n",
        "        model = GraphLevelGNN.load_from_checkpoint(pretrained_filename)\n",
        "    else:\n",
        "        pl.seed_everything(42)\n",
        "        model = GraphLevelGNN(c_in=tu_dataset.num_node_features,\n",
        "                              c_out=1 if tu_dataset.num_classes==2 else tu_dataset.num_classes,\n",
        "                              **model_kwargs)\n",
        "        trainer.fit(model, graph_train_loader, graph_val_loader)\n",
        "        model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
        "    # Test best model on validation and test set\n",
        "    train_result = trainer.test(model, graph_train_loader, verbose=False)\n",
        "    test_result = trainer.test(model, graph_test_loader, verbose=False)\n",
        "    result = {\"test\": test_result[0]['test_acc'], \"train\": train_result[0]['test_acc']}\n",
        "    return model, result"
      ],
      "metadata": {
        "id": "sr1Fttt0CZbq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, result = train_graph_classifier(model_name=\"GraphConv\",\n",
        "                                       c_hidden=256,\n",
        "                                       layer_name=\"GraphConv\",\n",
        "                                       num_layers=3,\n",
        "                                       dp_rate_linear=0.5,\n",
        "                                       dp_rate=0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4Dh2MoUCasa",
        "outputId": "e0b56f60-7197-4c89-be79-ced49b77533d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.0.2 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../saved_models/tutorial7/GraphLevelGraphConv.ckpt`\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: ../saved_models/tutorial7/GraphLevelGraphConv/lightning_logs\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found pretrained model, loading...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train performance: {100.0*result['train']:4.2f}%\")\n",
        "print(f\"Test performance:  {100.0*result['test']:4.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJC9MdbYCpcZ",
        "outputId": "a22d992a-fcd8-43cf-a3ad-cd5272a2d1e0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train performance: 93.28%\n",
            "Test performance:  92.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Jraph**"
      ],
      "metadata": {
        "id": "LOEQFSmhCq1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "\n",
        "# Create a DeviceArray from a regular NumPy array\n",
        "arr = jnp.array([1, 2, 3, 4, 5])\n",
        "\n",
        "# Or create a DeviceArray using jax.device_put\n",
        "from jax import device_put\n",
        "arr = device_put([1, 2, 3, 4, 5])\n"
      ],
      "metadata": {
        "id": "7uhDWcC-AtbM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_jraph_to_networkx_graph(jraph_graph: jraph.GraphsTuple) -> nx.Graph:\n",
        "  nodes, edges, receivers, senders, _, _, _ = jraph_graph\n",
        "  nx_graph = nx.DiGraph()\n",
        "  if nodes is None:\n",
        "    for n in range(jraph_graph.n_node[0]):\n",
        "      nx_graph.add_node(n)\n",
        "  else:\n",
        "    for n in range(jraph_graph.n_node[0]):\n",
        "      nx_graph.add_node(n, node_feature=nodes[n])\n",
        "  if edges is None:\n",
        "    for e in range(jraph_graph.n_edge[0]):\n",
        "      nx_graph.add_edge(int(senders[e]), int(receivers[e]))\n",
        "  else:\n",
        "    for e in range(jraph_graph.n_edge[0]):\n",
        "      nx_graph.add_edge(\n",
        "          int(senders[e]), int(receivers[e]), edge_feature=edges[e])\n",
        "  return nx_graph\n",
        "\n",
        "\n",
        "def draw_jraph_graph_structure(jraph_graph: jraph.GraphsTuple) -> None:\n",
        "  nx_graph = convert_jraph_to_networkx_graph(jraph_graph)\n",
        "  pos = nx.spring_layout(nx_graph)\n",
        "  nx.draw(\n",
        "      nx_graph, pos=pos, with_labels=True, node_size=500, font_color='yellow')"
      ],
      "metadata": {
        "id": "j7lAtohhCt1G"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download jraph version of MUTAG.\n",
        "!wget -P /tmp/ https://storage.googleapis.com/dm-educational/assets/graph-nets/jraph_datasets/mutag.pickle\n",
        "with open('/tmp/mutag.pickle', 'rb') as f:\n",
        "  mutag_ds = pickle.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XuK_1P4CwPZ",
        "outputId": "65f6c80e-3eb1-450b-9e04-b1f32d48550e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-13 19:56:49--  https://storage.googleapis.com/dm-educational/assets/graph-nets/jraph_datasets/mutag.pickle\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.207, 2607:f8b0:4023:c0d::cf, 2607:f8b0:4023:c03::cf, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 352981 (345K) [application/octet-stream]\n",
            "Saving to: ‘/tmp/mutag.pickle’\n",
            "\n",
            "\rmutag.pickle          0%[                    ]       0  --.-KB/s               \rmutag.pickle        100%[===================>] 344.71K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-02-13 19:56:49 (98.0 MB/s) - ‘/tmp/mutag.pickle’ saved [352981/352981]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(mutag_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5_-YRTiCzO5",
        "outputId": "a2356637-aecd-451a-a1ec-19b36a0c7ebf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "188"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the first graph\n",
        "g = mutag_ds[0]['input_graph']\n",
        "print(f'Number of nodes: {g.n_node[0]}')\n",
        "print(f'Number of edges: {g.n_edge[0]}')\n",
        "print(f'Node features shape: {g.nodes.shape}')\n",
        "print(f'Edge features shape: {g.edges.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4Da_IIIC3M0",
        "outputId": "03099bb3-856a-4f62-a36b-d3f5155ee204"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 17\n",
            "Number of edges: 38\n",
            "Node features shape: (17, 7)\n",
            "Edge features shape: (38, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "draw_jraph_graph_structure(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "uBCIluNZC4Lj",
        "outputId": "1e59121b-0fa4-42df-97c6-8c5a66dae8fe"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"475.2pt\" height=\"360pt\" viewBox=\"0 0 475.2 360\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-02-13T19:57:24.272865</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 360 \nL 475.2 360 \nL 475.2 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 86.145933 41.5924 \nQ 71.803761 47.737941 58.489253 53.443135 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 62.953654 53.706038 \nL 58.489253 53.443135 \nL 61.378216 50.029355 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 105.828971 43.232433 \nQ 116.120705 49.841581 125.471684 55.846594 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 123.186643 52.002301 \nL 125.471684 55.846594 \nL 121.025225 55.368051 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 57.460696 53.883866 \nQ 71.802868 47.738324 85.117376 42.033131 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 80.652975 41.770228 \nL 85.117376 42.033131 \nL 82.228413 45.44691 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 47.730706 69.457777 \nQ 48.181114 78.708575 48.577151 86.842661 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 50.380261 82.750132 \nL 48.577151 86.842661 \nL 46.384994 82.944656 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 48.631186 87.952472 \nQ 48.180778 78.701674 47.784741 70.567588 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 45.981631 74.660117 \nL 47.784741 70.567588 \nL 49.976898 74.465593 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 57.594601 106.483573 \nQ 72.251657 119.295366 86.066932 131.371355 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 84.371533 127.233043 \nL 86.066932 131.371355 \nL 81.739043 130.244687 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 86.906468 132.105197 \nQ 72.249413 119.293405 58.434137 107.217415 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 60.129536 111.355727 \nL 58.434137 107.217415 \nL 62.762026 108.344084 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 104.263232 132.741795 \nQ 118.489547 122.040301 131.822394 112.010902 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 127.42354 112.817181 \nL 131.822394 112.010902 \nL 129.828105 116.013753 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 100.682219 149.275108 \nQ 110.524249 167.30153 119.830511 184.346652 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 119.669091 179.87743 \nL 119.830511 184.346652 \nL 116.158281 181.794255 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 132.712105 111.341633 \nQ 118.485789 122.043128 105.152942 132.072526 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 109.551796 131.266247 \nL 105.152942 132.072526 \nL 107.147232 128.069676 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 140.116039 93.543944 \nQ 138.732801 83.553325 137.502897 74.670176 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 136.070376 78.906671 \nL 137.502897 74.670176 \nL 140.03258 78.358089 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 151.784706 109.342244 \nQ 168.185395 116.985707 183.572699 124.156887 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 180.791949 120.654398 \nL 183.572699 124.156887 \nL 179.102257 124.279993 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 126.407362 56.447468 \nQ 116.115628 49.83832 106.76465 43.833307 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 109.049691 47.6776 \nL 106.76465 43.833307 \nL 111.211109 44.31185 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 137.349825 73.564598 \nQ 138.733063 83.555217 139.962967 92.438366 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 141.395488 88.201872 \nL 139.962967 92.438366 \nL 137.433284 88.750453 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 184.584413 124.628392 \nQ 168.183724 116.984928 152.79642 109.813748 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 155.577169 113.316237 \nL 152.79642 109.813748 \nL 157.266861 109.690642 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path d=\"M 199.306651 139.54715 \nQ 203.150721 148.091283 206.536068 155.615823 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 206.718796 151.147421 \nL 206.536068 155.615823 \nL 203.070983 152.7886 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path d=\"M 206.994389 156.634525 \nQ 203.150319 148.090391 199.764972 140.565851 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 199.582244 145.034253 \nL 199.764972 140.565851 \nL 203.230056 143.393074 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path d=\"M 207.981014 177.41518 \nQ 204.811639 186.733638 202.002275 194.993611 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 205.183763 191.850662 \nL 202.002275 194.993611 \nL 201.396809 190.562651 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path d=\"M 201.643116 196.049595 \nQ 204.81249 186.731137 207.621855 178.471164 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 204.440366 181.614114 \nL 207.621855 178.471164 \nL 208.227321 182.902125 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path d=\"M 187.003323 204.880262 \nQ 161.885756 200.887776 137.872361 197.070801 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 141.508805 199.673929 \nL 137.872361 197.070801 \nL 142.13673 195.723522 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path d=\"M 206.888262 213.470706 \nQ 222.613634 225.623166 237.45435 237.09197 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 235.512271 233.06353 \nL 237.45435 237.09197 \nL 233.06635 236.228569 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path d=\"M 120.367002 185.329275 \nQ 110.524971 167.302853 101.21871 150.257731 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 101.38013 154.726953 \nL 101.21871 150.257731 \nL 104.890939 152.810128 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path d=\"M 136.76277 196.894429 \nQ 161.880337 200.886915 185.893731 204.70389 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 182.257287 202.100763 \nL 185.893731 204.70389 \nL 181.629363 206.051169 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path d=\"M 129.197572 205.76905 \nQ 133.654121 219.403521 137.763315 231.975285 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 138.421606 227.551864 \nL 137.763315 231.975285 \nL 134.619553 228.7946 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path d=\"M 138.109373 233.034025 \nQ 133.652824 219.399554 129.54363 206.827789 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 128.885339 211.25121 \nL 129.54363 206.827789 \nL 132.687392 210.008475 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path d=\"M 151.404896 249.013673 \nQ 171.352004 259.880202 190.317311 270.211878 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 187.761488 266.542033 \nL 190.317311 270.211878 \nL 185.847941 270.054629 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_28\">\n    <path d=\"M 191.292921 270.743358 \nQ 171.345813 259.876829 152.380506 249.545153 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 154.936329 253.214999 \nL 152.380506 249.545153 \nL 156.849877 249.702402 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_29\">\n    <path d=\"M 212.278087 276.740777 \nQ 242.284384 278.480156 271.17452 280.154834 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 267.296964 277.926706 \nL 271.17452 280.154834 \nL 267.065484 281.920002 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_30\">\n    <path d=\"M 272.286511 280.219293 \nQ 242.280215 278.479914 213.390078 276.805236 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 217.267635 279.033364 \nL 213.390078 276.805236 \nL 217.499115 275.040068 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_31\">\n    <path d=\"M 275.541988 272.960255 \nQ 265.318722 262.739954 255.88614 253.310108 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 257.300969 257.552543 \nL 255.88614 253.310108 \nL 260.128986 254.723706 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_32\">\n    <path d=\"M 294.454051 282.831486 \nQ 327.775476 288.782117 359.99628 294.536196 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 356.410181 291.864139 \nL 359.99628 294.536196 \nL 355.706975 295.801841 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_33\">\n    <path d=\"M 238.340704 237.776938 \nQ 222.615333 225.624478 207.774617 214.155674 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 209.716695 218.184114 \nL 207.774617 214.155674 \nL 212.162616 215.019075 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_34\">\n    <path d=\"M 255.094613 252.518811 \nQ 265.317879 262.739112 274.750461 272.168958 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 273.335632 267.926523 \nL 274.750461 272.168958 \nL 270.507615 270.75536 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_35\">\n    <path d=\"M 361.103292 294.733889 \nQ 327.781866 288.783258 295.561062 283.029179 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 299.147162 285.701236 \nL 295.561062 283.029179 \nL 299.850368 281.763533 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_36\">\n    <path d=\"M 381.871732 302.138196 \nQ 395.542599 309.753197 408.236738 316.824137 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 405.715535 313.130421 \nL 408.236738 316.824137 \nL 403.769044 316.624869 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_37\">\n    <path d=\"M 382.626856 292.920598 \nQ 400.058113 286.660008 416.437144 280.777334 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 411.996549 280.247129 \nL 416.437144 280.777334 \nL 413.348624 284.011687 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_38\">\n    <path d=\"M 409.21789 317.370662 \nQ 395.547023 309.755661 382.852884 302.684721 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 385.374087 306.378437 \nL 382.852884 302.684721 \nL 387.320578 302.883988 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"patch_39\">\n    <path d=\"M 417.49325 280.398025 \nQ 400.061993 286.658615 383.682962 292.541289 \n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: none; stroke: #1a1a1a; stroke-linecap: round\"/>\n    <path d=\"M 388.123557 293.071493 \nL 383.682962 292.541289 \nL 386.771482 289.306936 \nz\n\" clip-path=\"url(#p9dabeaa287)\" style=\"fill: #1a1a1a; stroke: #1a1a1a; stroke-linecap: round\"/>\n   </g>\n   <g id=\"PathCollection_1\">\n    <defs>\n     <path id=\"m4e47e5933b\" d=\"M 0 11.18034 \nC 2.965061 11.18034 5.80908 10.002309 7.905694 7.905694 \nC 10.002309 5.80908 11.18034 2.965061 11.18034 0 \nC 11.18034 -2.965061 10.002309 -5.80908 7.905694 -7.905694 \nC 5.80908 -10.002309 2.965061 -11.18034 0 -11.18034 \nC -2.965061 -11.18034 -5.80908 -10.002309 -7.905694 -7.905694 \nC -10.002309 -5.80908 -11.18034 -2.965061 -11.18034 0 \nC -11.18034 2.965061 -10.002309 5.80908 -7.905694 7.905694 \nC -5.80908 10.002309 -2.965061 11.18034 0 11.18034 \nz\n\" style=\"stroke: #1f78b4\"/>\n    </defs>\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <use xlink:href=\"#m4e47e5933b\" x=\"96.419852\" y=\"37.190083\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n     <use xlink:href=\"#m4e47e5933b\" x=\"47.186777\" y=\"58.286183\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n     <use xlink:href=\"#m4e47e5933b\" x=\"49.175115\" y=\"99.124066\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n     <use xlink:href=\"#m4e47e5933b\" x=\"95.325954\" y=\"139.464704\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n     <use xlink:href=\"#m4e47e5933b\" x=\"141.649382\" y=\"104.618724\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n     <use xlink:href=\"#m4e47e5933b\" x=\"135.816482\" y=\"62.489818\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n     <use xlink:href=\"#m4e47e5933b\" x=\"194.719736\" y=\"129.351911\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n     <use xlink:href=\"#m4e47e5933b\" x=\"211.581304\" y=\"166.829763\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n     <use xlink:href=\"#m4e47e5933b\" x=\"198.042826\" y=\"206.635012\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n     <use xlink:href=\"#m4e47e5933b\" x=\"125.723267\" y=\"195.139679\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n     <use xlink:href=\"#m4e47e5933b\" x=\"141.583679\" y=\"243.663396\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n     <use xlink:href=\"#m4e47e5933b\" x=\"201.114139\" y=\"276.093635\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n     <use xlink:href=\"#m4e47e5933b\" x=\"283.45046\" y=\"280.866435\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n     <use xlink:href=\"#m4e47e5933b\" x=\"247.186141\" y=\"244.612631\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n     <use xlink:href=\"#m4e47e5933b\" x=\"372.106883\" y=\"296.69894\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n     <use xlink:href=\"#m4e47e5933b\" x=\"418.982739\" y=\"322.809917\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n     <use xlink:href=\"#m4e47e5933b\" x=\"428.013223\" y=\"276.619683\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n    </g>\n   </g>\n   <g id=\"text_1\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 0 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(92.602352 40.501333) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-30\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_2\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 1 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(43.369277 61.597433) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-31\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_3\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 2 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(45.357615 102.435316) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-32\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_4\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 3 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(91.508454 142.775954) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-33\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_5\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 4 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(137.831882 107.929974) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-34\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_6\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 5 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(131.998982 65.801068) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-35\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_7\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 6 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(190.902236 132.663161) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-36\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_8\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 7 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(207.763804 170.141013) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-37\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_9\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 8 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(194.225326 209.946262) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-38\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_10\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 9 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(121.905767 198.450929) scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"DejaVuSans-39\" d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-39\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_11\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 10 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(133.948679 246.974646) scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-31\"/>\n      <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_12\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 11 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(193.479139 279.404885) scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-31\"/>\n      <use xlink:href=\"#DejaVuSans-31\" x=\"63.623047\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_13\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 12 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(275.81546 284.177685) scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-31\"/>\n      <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_14\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 13 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(239.551141 247.923881) scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-31\"/>\n      <use xlink:href=\"#DejaVuSans-33\" x=\"63.623047\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_15\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 14 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(364.471883 300.01019) scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-31\"/>\n      <use xlink:href=\"#DejaVuSans-34\" x=\"63.623047\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_16\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 15 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(411.347739 326.121167) scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-31\"/>\n      <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"text_17\">\n    <g clip-path=\"url(#p9dabeaa287)\">\n     <!-- 16 -->\n     <g style=\"fill: #ffff00\" transform=\"translate(420.378223 279.930933) scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-31\"/>\n      <use xlink:href=\"#DejaVuSans-36\" x=\"63.623047\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p9dabeaa287\">\n   <rect x=\"7.2\" y=\"7.2\" width=\"460.8\" height=\"345.6\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "application/pdf": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_simplified_gcn(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
        "  # Unpack GraphsTuple\n",
        "  nodes, _, receivers, senders, _, _, _ = graph\n",
        "\n",
        "  # 1. Update node features\n",
        "  # For simplicity, we will first use an identify function here, and replace it\n",
        "  # with a trainable MLP block later.\n",
        "  update_node_fn = lambda nodes: nodes\n",
        "  nodes = update_node_fn(nodes)\n",
        "\n",
        "  # 2. Aggregate node features over nodes in neighborhood\n",
        "  # Equivalent to jnp.sum(n_node), but jittable\n",
        "  total_num_nodes = tree.tree_leaves(nodes)[0].shape[0]\n",
        "  aggregate_nodes_fn = jax.ops.segment_sum\n",
        "\n",
        "  # Compute new node features by aggregating messages from neighboring nodes\n",
        "  nodes = tree.tree_map(lambda x: aggregate_nodes_fn(x[senders], receivers,\n",
        "                                        total_num_nodes), nodes)\n",
        "  out_graph = graph._replace(nodes=nodes)\n",
        "  return out_graph"
      ],
      "metadata": {
        "id": "ZgeGWHXIC7kg"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download jraph version of Cora.\n",
        "!wget -P /tmp/ https://storage.googleapis.com/dm-educational/assets/graph-nets/jraph_datasets/cora.pickle\n",
        "with open('/tmp/cora.pickle', 'rb') as f:\n",
        "  cora_ds = pickle.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXNvMh2-C-zR",
        "outputId": "672b573b-3343-4d06-f961-2011270060b8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-13 19:57:59--  https://storage.googleapis.com/dm-educational/assets/graph-nets/jraph_datasets/cora.pickle\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.207, 2607:f8b0:4023:c03::cf, 2607:f8b0:4023:c0b::cf, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15618018 (15M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/cora.pickle’\n",
            "\n",
            "\rcora.pickle           0%[                    ]       0  --.-KB/s               \rcora.pickle         100%[===================>]  14.89M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2024-02-13 19:58:00 (171 MB/s) - ‘/tmp/cora.pickle’ saved [15618018/15618018]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_test_split_edges(graph: jraph.GraphsTuple,\n",
        "                               val_perc: float = 0.05,\n",
        "                               test_perc: float = 0.1):\n",
        "  \"\"\"Split edges in input graph into train, val and test splits.\n",
        "\n",
        "  For val and test sets, also include negative edges.\n",
        "  Based on torch_geometric.utils.train_test_split_edges.\n",
        "  \"\"\"\n",
        "  mask = graph.senders < graph.receivers\n",
        "  senders = graph.senders[mask]\n",
        "  receivers = graph.receivers[mask]\n",
        "  num_val = int(val_perc * senders.shape[0])\n",
        "  num_test = int(test_perc * senders.shape[0])\n",
        "  permuted_indices = onp.random.permutation(range(senders.shape[0]))\n",
        "  senders = senders[permuted_indices]\n",
        "  receivers = receivers[permuted_indices]\n",
        "  if graph.edges is not None:\n",
        "    edges = graph.edges[permuted_indices]\n",
        "\n",
        "  val_senders = senders[:num_val]\n",
        "  val_receivers = receivers[:num_val]\n",
        "  if graph.edges is not None:\n",
        "    val_edges = edges[:num_val]\n",
        "\n",
        "  test_senders = senders[num_val:num_val + num_test]\n",
        "  test_receivers = receivers[num_val:num_val + num_test]\n",
        "  if graph.edges is not None:\n",
        "    test_edges = edges[num_val:num_val + num_test]\n",
        "\n",
        "  train_senders = senders[num_val + num_test:]\n",
        "  train_receivers = receivers[num_val + num_test:]\n",
        "  train_edges = None\n",
        "  if graph.edges is not None:\n",
        "    train_edges = edges[num_val + num_test:]\n",
        "\n",
        "  # make training edges undirected by adding reverse edges back in\n",
        "  train_senders_undir = jnp.concatenate((train_senders, train_receivers))\n",
        "  train_receivers_undir = jnp.concatenate((train_receivers, train_senders))\n",
        "  train_senders = train_senders_undir\n",
        "  train_receivers = train_receivers_undir\n",
        "\n",
        "  # Negative edges.\n",
        "  num_nodes = graph.n_node[0]\n",
        "  # Create a negative adjacency mask, s.t. mask[i, j] = True iff edge i->j does\n",
        "  # not exist in the original graph.\n",
        "  neg_adj_mask = onp.ones((num_nodes, num_nodes), dtype=onp.uint8)\n",
        "  # upper triangular part\n",
        "  neg_adj_mask = onp.triu(neg_adj_mask, k=1)\n",
        "  neg_adj_mask[graph.senders, graph.receivers] = 0\n",
        "  neg_adj_mask = neg_adj_mask.astype(bool)\n",
        "  neg_senders, neg_receivers = neg_adj_mask.nonzero()\n",
        "\n",
        "  perm = onp.random.permutation(range(len(neg_senders)))\n",
        "  neg_senders = neg_senders[perm]\n",
        "  neg_receivers = neg_receivers[perm]\n",
        "\n",
        "  val_neg_senders = neg_senders[:num_val]\n",
        "  val_neg_receivers = neg_receivers[:num_val]\n",
        "  test_neg_senders = neg_senders[num_val:num_val + num_test]\n",
        "  test_neg_receivers = neg_receivers[num_val:num_val + num_test]\n",
        "\n",
        "  train_graph = jraph.GraphsTuple(\n",
        "      nodes=graph.nodes,\n",
        "      edges=train_edges,\n",
        "      senders=train_senders,\n",
        "      receivers=train_receivers,\n",
        "      n_node=graph.n_node,\n",
        "      n_edge=jnp.array([len(train_senders)]),\n",
        "      globals=graph.globals)\n",
        "\n",
        "  return train_graph, neg_adj_mask, val_senders, val_receivers, val_neg_senders, val_neg_receivers, test_senders, test_receivers, test_neg_senders, test_neg_receivers"
      ],
      "metadata": {
        "id": "bAfj9P0YDEGJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = cora_ds[0]['input_graph']\n",
        "\n",
        "train_graph, neg_adj_mask, val_pos_senders, val_pos_receivers, val_neg_senders, val_neg_receivers, test_pos_senders, test_pos_receivers, test_neg_senders, test_neg_receivers = train_val_test_split_edges(graph)"
      ],
      "metadata": {
        "id": "98GQ7BRaDHay"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train set: {train_graph.senders.shape[0]} positive edges, we will sample the same number of negative edges at runtime')\n",
        "print(f'Val set: {val_pos_senders.shape[0]} positive edges, {val_neg_senders.shape[0]} negative edges')\n",
        "print(f'Test set: {test_pos_senders.shape[0]} positive edges, {test_neg_senders.shape[0]} negative edges')\n",
        "print(f'Negative adjacency mask shape: {neg_adj_mask.shape}')\n",
        "print(f'Numbe of negative edges to sample from: {neg_adj_mask.sum()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aQFUvWIDK8Y",
        "outputId": "3aa3f41d-a3e6-4aee-f05a-abd1296cfcfa"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 8976 positive edges, we will sample the same number of negative edges at runtime\n",
            "Val set: 263 positive edges, 263 negative edges\n",
            "Test set: 527 positive edges, 527 negative edges\n",
            "Negative adjacency mask shape: (2708, 2708)\n",
            "Numbe of negative edges to sample from: 3660000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@jraph.concatenated_args\n",
        "def node_update_fn(feats: jnp.ndarray) -> jnp.ndarray:\n",
        "  \"\"\"Node update function for graph net.\"\"\"\n",
        "  net = hk.Sequential([hk.Linear(128), jax.nn.relu, hk.Linear(64)])\n",
        "  return net(feats)\n",
        "\n",
        "\n",
        "def net_fn(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
        "  \"\"\"Network definition.\"\"\"\n",
        "  graph = graph._replace(globals=jnp.zeros([graph.n_node.shape[0], 1]))\n",
        "  net = jraph.GraphNetwork(\n",
        "      update_node_fn=node_update_fn, update_edge_fn=None, update_global_fn=None)\n",
        "  return net(graph)\n",
        "\n",
        "\n",
        "def decode(pred_graph: jraph.GraphsTuple, senders: jnp.ndarray,\n",
        "           receivers: jnp.ndarray) -> jnp.ndarray:\n",
        "  \"\"\"Given a set of candidate edges, take dot product of respective nodes.\n",
        "\n",
        "  Args:\n",
        "    pred_graph: input graph.\n",
        "    senders: Senders of candidate edges.\n",
        "    receivers: Receivers of candidate edges.\n",
        "\n",
        "  Returns:\n",
        "    For each edge, computes dot product of the features of the two nodes.\n",
        "\n",
        "  \"\"\"\n",
        "  return jnp.squeeze(\n",
        "      jnp.sum(pred_graph.nodes[senders] * pred_graph.nodes[receivers], axis=1))"
      ],
      "metadata": {
        "id": "y8rnuk6tDNxT"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def compute_bce_with_logits_loss(x: jnp.ndarray, y: jnp.ndarray) -> jnp.ndarray:\n",
        "  \"\"\"Computes binary cross-entropy with logits loss.\n",
        "\n",
        "  Combines sigmoid and BCE, and uses log-sum-exp trick for numerical stability.\n",
        "  See https://stackoverflow.com/a/66909858 if you want to learn more.\n",
        "\n",
        "  Args:\n",
        "    x: Predictions (logits).\n",
        "    y: Labels.\n",
        "\n",
        "  Returns:\n",
        "    Binary cross-entropy loss with mean aggregation.\n",
        "\n",
        "  \"\"\"\n",
        "  max_val = jnp.clip(x, 0, None)\n",
        "  loss = x - x * y + max_val + jnp.log(\n",
        "      jnp.exp(-max_val) + jnp.exp((-x - max_val)))\n",
        "  return loss.mean()\n",
        "\n",
        "\n",
        "def compute_loss(params: hk.Params, graph: jraph.GraphsTuple,\n",
        "                 senders: jnp.ndarray, receivers: jnp.ndarray,\n",
        "                 labels: jnp.ndarray,\n",
        "                 net: hk.Transformed) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
        "  \"\"\"Computes loss.\"\"\"\n",
        "  pred_graph = net.apply(params, graph)\n",
        "  preds = decode(pred_graph, senders, receivers)\n",
        "  loss = compute_bce_with_logits_loss(preds, labels)\n",
        "  return loss, preds\n",
        "\n",
        "\n",
        "def compute_roc_auc_score(preds: jnp.ndarray,\n",
        "                          labels: jnp.ndarray) -> jnp.ndarray:\n",
        "  \"\"\"Computes roc auc (area under the curve) score for classification.\"\"\"\n",
        "  s = jax.nn.sigmoid(preds)\n",
        "  roc_auc = roc_auc_score(labels, s)\n",
        "  return roc_auc"
      ],
      "metadata": {
        "id": "cyr1wxj0DUEh"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "from typing import Tuple\n",
        "import jax\n",
        "\n",
        "def negative_sampling(\n",
        "    graph: jraph.GraphsTuple, num_neg_samples: int,\n",
        "    key: jnp.ndarray) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
        "  \"\"\"Samples negative edges, i.e. edges that don't exist in the input graph.\"\"\"\n",
        "  num_nodes = graph.n_node[0]\n",
        "  total_possible_edges = num_nodes**2\n",
        "  # convert 2D edge indices to 1D representation.\n",
        "  pos_idx = graph.senders * num_nodes + graph.receivers\n",
        "\n",
        "  # Percentage to oversample edges, so most likely will sample enough neg edges.\n",
        "  alpha = jnp.abs(1 / (1 - 1.1 *\n",
        "                       (graph.senders.shape[0] / total_possible_edges)))\n",
        "\n",
        "  perm = jax.random.randint(\n",
        "      key,\n",
        "      shape=(int(alpha * num_neg_samples),),\n",
        "      minval=0,\n",
        "      maxval=total_possible_edges,\n",
        "      dtype=jnp.uint32)\n",
        "\n",
        "  # mask where sampled edges are positive edges.\n",
        "  mask = jnp.isin(perm, pos_idx)\n",
        "  # remove positive edges.\n",
        "  perm = perm[~mask][:num_neg_samples]\n",
        "\n",
        "  # convert 1d back to 2d edge indices.\n",
        "  neg_senders = perm // num_nodes\n",
        "  neg_receivers = perm % num_nodes\n",
        "\n",
        "  return neg_senders, neg_receivers\n"
      ],
      "metadata": {
        "id": "PnVRrvzSDYs4"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset: List[Dict[str, Any]], num_epochs: int) -> hk.Params:\n",
        "  \"\"\"Training loop.\"\"\"\n",
        "  key = jax.random.PRNGKey(42)\n",
        "  # Transform impure `net_fn` to pure functions with hk.transform.\n",
        "  net = hk.without_apply_rng(hk.transform(net_fn))\n",
        "  # Get a candidate graph and label to initialize the network.\n",
        "  graph = dataset[0]['input_graph']\n",
        "\n",
        "  train_graph, _, val_pos_s, val_pos_r, val_neg_s, val_neg_r, test_pos_s, \\\n",
        "      test_pos_r, test_neg_s, test_neg_r = train_val_test_split_edges(\n",
        "      graph)\n",
        "\n",
        "  # Prepare the validation and test data.\n",
        "  val_senders = jnp.concatenate((val_pos_s, val_neg_s))\n",
        "  val_receivers = jnp.concatenate((val_pos_r, val_neg_r))\n",
        "  val_labels = jnp.concatenate(\n",
        "      (jnp.ones(len(val_pos_s)), jnp.zeros(len(val_neg_s))))\n",
        "  test_senders = jnp.concatenate((test_pos_s, test_neg_s))\n",
        "  test_receivers = jnp.concatenate((test_pos_r, test_neg_r))\n",
        "  test_labels = jnp.concatenate(\n",
        "      (jnp.ones(len(test_pos_s)), jnp.zeros(len(test_neg_s))))\n",
        "  # Initialize the network.\n",
        "  params = net.init(key, train_graph)\n",
        "  # Initialize the optimizer.\n",
        "  opt_init, opt_update = optax.adam(1e-4)\n",
        "  opt_state = opt_init(params)\n",
        "\n",
        "  compute_loss_fn = functools.partial(compute_loss, net=net)\n",
        "  # We jit the computation of our loss, since this is the main computation.\n",
        "  # Using jax.jit means that we will use a single accelerator. If you want\n",
        "  # to use more than 1 accelerator, use jax.pmap. More information can be\n",
        "  # found in the jax documentation.\n",
        "  compute_loss_fn = jax.jit(jax.value_and_grad(compute_loss_fn, has_aux=True))\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    num_neg_samples = train_graph.senders.shape[0]\n",
        "    train_neg_senders, train_neg_receivers = negative_sampling(\n",
        "        train_graph, num_neg_samples=num_neg_samples, key=key)\n",
        "    train_senders = jnp.concatenate((train_graph.senders, train_neg_senders))\n",
        "    train_receivers = jnp.concatenate(\n",
        "        (train_graph.receivers, train_neg_receivers))\n",
        "    train_labels = jnp.concatenate(\n",
        "        (jnp.ones(len(train_graph.senders)), jnp.zeros(len(train_neg_senders))))\n",
        "\n",
        "    (train_loss,\n",
        "     train_preds), grad = compute_loss_fn(params, train_graph, train_senders,\n",
        "                                          train_receivers, train_labels)\n",
        "\n",
        "    updates, opt_state = opt_update(grad, opt_state, params)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "    if epoch % 10 == 0 or epoch == (num_epochs - 1):\n",
        "      train_roc_auc = compute_roc_auc_score(train_preds, train_labels)\n",
        "      val_loss, val_preds = compute_loss(params, train_graph, val_senders,\n",
        "                                         val_receivers, val_labels, net)\n",
        "      val_roc_auc = compute_roc_auc_score(val_preds, val_labels)\n",
        "      print(f'epoch: {epoch}, train_loss: {train_loss:.3f}, '\n",
        "            f'train_roc_auc: {train_roc_auc:.3f}, val_loss: {val_loss:.3f}, '\n",
        "            f'val_roc_auc: {val_roc_auc:.3f}')\n",
        "  test_loss, test_preds = compute_loss(params, train_graph, test_senders,\n",
        "                                       test_receivers, test_labels, net)\n",
        "  test_roc_auc = compute_roc_auc_score(test_preds, test_labels)\n",
        "  print('Training finished')\n",
        "  print(\n",
        "      f'epoch: {epoch}, test_loss: {test_loss:.3f}, test_roc_auc: {test_roc_auc:.3f}'\n",
        "  )\n",
        "  return params"
      ],
      "metadata": {
        "id": "WsWeJggTDblQ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = train(cora_ds, num_epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEqD4B5RDf9B",
        "outputId": "c34dbf3d-06b0-4479-983b-ac6646c0420b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, train_loss: 0.690, train_roc_auc: 0.601, val_loss: 0.691, val_roc_auc: 0.583\n",
            "epoch: 10, train_loss: 0.685, train_roc_auc: 0.701, val_loss: 0.688, val_roc_auc: 0.631\n",
            "epoch: 20, train_loss: 0.680, train_roc_auc: 0.760, val_loss: 0.686, val_roc_auc: 0.659\n",
            "epoch: 30, train_loss: 0.673, train_roc_auc: 0.791, val_loss: 0.682, val_roc_auc: 0.675\n",
            "epoch: 40, train_loss: 0.663, train_roc_auc: 0.812, val_loss: 0.678, val_roc_auc: 0.691\n",
            "epoch: 50, train_loss: 0.651, train_roc_auc: 0.834, val_loss: 0.671, val_roc_auc: 0.710\n",
            "epoch: 60, train_loss: 0.636, train_roc_auc: 0.854, val_loss: 0.662, val_roc_auc: 0.729\n",
            "epoch: 70, train_loss: 0.617, train_roc_auc: 0.870, val_loss: 0.650, val_roc_auc: 0.747\n",
            "epoch: 80, train_loss: 0.594, train_roc_auc: 0.883, val_loss: 0.637, val_roc_auc: 0.764\n",
            "epoch: 90, train_loss: 0.570, train_roc_auc: 0.890, val_loss: 0.621, val_roc_auc: 0.774\n",
            "epoch: 100, train_loss: 0.545, train_roc_auc: 0.895, val_loss: 0.607, val_roc_auc: 0.783\n",
            "epoch: 110, train_loss: 0.522, train_roc_auc: 0.901, val_loss: 0.596, val_roc_auc: 0.789\n",
            "epoch: 120, train_loss: 0.501, train_roc_auc: 0.909, val_loss: 0.589, val_roc_auc: 0.794\n",
            "epoch: 130, train_loss: 0.481, train_roc_auc: 0.918, val_loss: 0.585, val_roc_auc: 0.798\n",
            "epoch: 140, train_loss: 0.463, train_roc_auc: 0.927, val_loss: 0.582, val_roc_auc: 0.801\n",
            "epoch: 150, train_loss: 0.447, train_roc_auc: 0.936, val_loss: 0.582, val_roc_auc: 0.804\n",
            "epoch: 160, train_loss: 0.431, train_roc_auc: 0.944, val_loss: 0.583, val_roc_auc: 0.807\n",
            "epoch: 170, train_loss: 0.416, train_roc_auc: 0.951, val_loss: 0.584, val_roc_auc: 0.809\n",
            "epoch: 180, train_loss: 0.401, train_roc_auc: 0.957, val_loss: 0.586, val_roc_auc: 0.811\n",
            "epoch: 190, train_loss: 0.387, train_roc_auc: 0.963, val_loss: 0.588, val_roc_auc: 0.813\n",
            "epoch: 199, train_loss: 0.374, train_roc_auc: 0.967, val_loss: 0.591, val_roc_auc: 0.814\n",
            "Training finished\n",
            "epoch: 199, test_loss: 0.585, test_roc_auc: 0.827\n"
          ]
        }
      ]
    }
  ]
}